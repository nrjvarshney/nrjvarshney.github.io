<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Neeraj Varshney | Publications</title>
  <meta name="description" content="Personal website of Neeraj Varshney">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="../assets/css/all.min.css">
  <link rel="stylesheet" href="../assets/css/academicons.min.css">
  <link rel="stylesheet" href="../assets/css/main.css">
  <link rel="canonical" href="../publications/index.html">
  <link rel="shortcut icon" type="image/x-icon" href="../assets/img/logo.png" />
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="../index.html"><span class="font-weight-bold">Neeraj</span> Varshney</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="../index.html">
              About
              
            </a>
          </li>
          
            
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="/cv/">
                    CV
                    
                  </a>
              </li>
            
          
            
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="../projects/index.html">
                    Articles
                    
                  </a>
              </li>
            
          
            
              <li class="nav-item navbar-active font-weight-bold">
                  <a class="nav-link" href="../publications/index.html">
                    Publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
              </li>
            
          
            
              <!-- <li class="nav-item ">
                  <a class="nav-link" href="../resources/index.html">
                    Resources
                    
                  </a>
              </li>
             -->
          
            
          
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
<!--   <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress> -->

  <!-- Content -->
  <div class="content">
    
  <!-- <h1>Publications</h1>
  <h6></h6>
 -->


<!-- <div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          AAMAS
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Methods and Mechanisms for Interactive Novelty Handling in Adversarial Environments</h5>
      <div>
        <p class="periodical font-italic">
          
            The 22nd International Conference on Autonomous Agents and Multiagent Systems
        
      </p>
      <p  class="periodical font">
 

      </div>
  
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>
 -->



<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          NAACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Accelerating LLM Inference by Enabling Intermediate Layer Decoding</h5>
      <div class="author">
        <nobr><em>Neeraj Varshney</em></nobr>,  <a target="_blank">Agneet Chatterjee</a>, <a target="_blank">Mihir Parmar</a>, and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <!-- <p class="periodical font-italic">
          
            Preprint
        
      </p> -->
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#decoding-abstract" role="button" aria-expanded="false" aria-controls="decoding-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#decoding-bibtex" role="button" aria-expanded="false" aria-controls="decoding-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2024.naacl.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2310.18581" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="decoding-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Large Language Models (LLMs) have achieved remarkable performance across a wide variety of natural language tasks; however, their large size makes their inference slow and computationally expensive which poses a practical challenge for resource constrained real-world applications. Focusing on this problem, we propose to instruction tune LLMs in a way that enables intermediate layer decoding for efficiently generating text, but importantly without compromising the quality of the generation. Specifically, we instruction tune LLMs with additional explicit Losses from the InTermediate layErs (LITE) and show that it enables these layers to acquire 'good' generation ability without affecting the generation ability of the final layer. We perform 'dynamic confidence-based early exiting' at token level from the intermediate layers which improves the efficiency of inference while maintaining the generation quality. We conduct comprehensive experiments by instruction tuning LLaMA-2 models on the widely used Alpaca dataset and holistically evaluate on four different human-instruction test sets: Vicuna, WizardLM, Koala, and Self-Instruct. We show that 'dynamic early exiting' achieves consistent and considerable cost improvements (37.86% on average) while maintaining the generation quality of the responses. We further conduct a thorough analysis of the results over several important aspects, such as comparing the semantic similarity of the outputs and dissecting the efficiency improvements by comparing the number of tokens generated in the output. In summary, our work contributes to improving the efficiency of LLM inference while maintaining the generation quality, a crucial step en route to enabling their widespread adoption.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="decoding-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @article{varshney2023accelerating,
  title={Accelerating LLM Inference by Enabling Intermediate Layer Decoding},
  author={Varshney, Neeraj and Chatterjee, Agneet and Parmar, Mihir and Baral, Chitta},
  journal={arXiv preprint arXiv:2310.18581},
  year={2023}
}</pre>

          </div>
        </div>
      </div> 
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2024</h3>
    </div>
  </div>

<!-- -------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          Preprint
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0"><i>A Stitch in Time Saves Nine:</i> Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation</h5>
      <div class="author">
        <nobr><em>Neeraj Varshney</em></nobr>,  <a href="https://scholar.google.com/citations?user=qwo2A24AAAAJ&hl=en" target="_blank">Wenlin Yao</a>, <a href="https://scholar.google.com.hk/citations?user=i5ETuuQAAAAJ&hl=en" target="_blank">Hongming Zhang</a>, <a href="https://chenjianshu.github.io/" target="_blank">Jianshu Chen</a>, and <a href="https://scholar.google.com/citations?user=tMY31_gAAAAJ&hl=en" target="_blank">Dong Yu</a>
          
      </div>
      <div>
        <!-- <p class="periodical font-italic">
          
            Preprint
        
      </p> -->
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#hallucinations-abstract" role="button" aria-expanded="false" aria-controls="hallucinations-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#hallucinations-bibtex" role="button" aria-expanded="false" aria-controls="hallucinations-bibtex">BibTeX</a>                
          
            <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://2023.aclweb.org/" target="_blank">Publisher</a>                   -->
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2307.03987" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="hallucinations-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Recently developed large language models have achieved remarkable success in generating fluent and coherent text. However, these models often tend to 'hallucinate' which critically hampers their reliability. In this work, we address this crucial problem and propose an approach that actively detects and mitigates hallucinations during the generation process. Specifically, we first identify the candidates of potential hallucination leveraging the model's logit output values, check their correctness through a validation procedure, mitigate the detected hallucinations, and then continue with the generation process. Through extensive experiments with GPT-3.5 (text-davinci-003) on the 'article generation task', we first demonstrate the individual efficacy of our detection and mitigation techniques. Specifically, the detection technique achieves a recall of ~88% and the mitigation technique successfully mitigates 57.6% of the correctly detected hallucinations. Importantly, our mitigation technique does not introduce new hallucinations even in the case of incorrectly detected hallucinations, i.e., false positives. Then, we show that the proposed active detection and mitigation approach successfully reduces the hallucinations of the GPT-3.5 model from 47.5% to 14.5% on average. We further demonstrate the effectiveness and wide applicability of our approach through additional studies including performance on different types of questions (multi-hop and false premise questions) and with another LLM from a different model family (Vicuna). In summary, our work contributes to improving the reliability and trustworthiness of large language models, a crucial step en route to enabling their widespread adoption in real-world applications.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="hallucinations-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @article{varshney2023stitch,
  title={A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023}
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>

<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          Preprint
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness</h5>
      <div class="author">
        <nobr><em>Neeraj Varshney</em></nobr>,  <a target="_blank">Pavel Dolin</a>, <a target="_blank">Agastya Seth</a>, and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <!-- <p class="periodical font-italic">
          
            Preprint
        
      </p> -->
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#defending-abstract" role="button" aria-expanded="false" aria-controls="defending-abstract">Abstract</a>        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#defending-bibtex" role="button" aria-expanded="false" aria-controls="defending-bibtex">BibTeX</a>                 -->
          
            <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://2023.aclweb.org/" target="_blank">Publisher</a>                   -->
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2401.00287" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="defending-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            As Large Language Models (LLMs) play an increasingly pivotal role in natural language processing applications, their safety concerns become critical areas of NLP research. This paper presents Safety and Over-Defensiveness Evaluation (SODE) benchmark: a collection of diverse safe and unsafe prompts with carefully designed evaluation methods that facilitate systematic evaluation, comparison, and analysis over 'safety' and 'over-defensiveness.' With SODE, we study a variety of LLM defense strategies over multiple state-of-the-art LLMs, which reveals several interesting and important findings, such as (a) the widely popular 'self-checking' techniques indeed improve the safety against unsafe inputs, but this comes at the cost of extreme over-defensiveness on the safe inputs, (b) providing a safety instruction along with in-context exemplars (of both safe and unsafe inputs) consistently improves safety and also mitigates undue over-defensiveness of the models, (c) providing contextual knowledge easily breaks the safety guardrails and makes the models more vulnerable to generating unsafe responses. Overall, our work reveals numerous such critical findings that we believe will pave the way and facilitate further research in improving the safety of LLMs.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="defending-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @article{varshney2023accelerating,
  title={Accelerating LLM Inference by Enabling Intermediate Layer Decoding},
  author={Varshney, Neeraj and Chatterjee, Agneet and Parmar, Mihir and Baral, Chitta},
  journal={arXiv preprint arXiv:2310.18581},
  year={2023}
}</pre>

          </div>
        </div>
      </div> 
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>

<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          EMNLP
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">LogicAttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference</h5>
      <div class="author">
        Mutsumi Nakamura, Santosh Mashetty, Mihir Parmar, <nobr><em>Neeraj Varshney</em></nobr> and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            Conference on Empirical Methods in Natural Language Processing 2023
        
      </p>
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#logicattack-abstract" role="button" aria-expanded="false" aria-controls="logicattack-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#logicattack-bibtex" role="button" aria-expanded="false" aria-controls="logicattack-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2023.emnlp.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2023.findings-emnlp.889/" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="logicattack-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Recently Large Language Models (LLMs) such as GPT-3, ChatGPT, and FLAN have led to impressive progress in Natural Language Inference (NLI) tasks. However, these models may rely on simple heuristics or artifacts in the evaluation data to achieve their high performance, which suggests that they still suffer from logical inconsistency. To assess the logical consistency of these models, we propose a LogicAttack, a method to attack NLI models using diverse logical forms of premise and hypothesis, providing a more robust evaluation of their performance. Our approach leverages a range of inference rules from propositional logic, such as Modus Tollens and Bidirectional Dilemma, to generate effective adversarial attacks and identify common vulnerabilities across multiple NLI models. We achieve an average ~53% Attack Success Rate (ASR) across multiple logic-based attacks. Moreover, we demonstrate that incorporating generated attack samples into training enhances the logical reasoning ability of the target model and decreases its vulnerability to logic-based attacks. Data and source code are available at https://github.com/msantoshmadhav/LogicAttack.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="logicattack-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          </pre>
@inproceedings{nakamura-etal-2023-logicattack,
    title = "{L}ogic{A}ttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference",
    author = "Nakamura, Mutsumi  and
      Mashetty, Santosh  and
      Parmar, Mihir  and
      Varshney, Neeraj  and
      Baral, Chitta",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.889",
    pages = "13322--13334",
    abstract = "Recently Large Language Models (LLMs) such as GPT-3, ChatGPT, and FLAN have led to impressive progress in Natural Language Inference (NLI) tasks. However, these models may rely on simple heuristics or artifacts in the evaluation data to achieve their high performance, which suggests that they still suffer from logical inconsistency. To assess the logical consistency of these models, we propose a LogicAttack, a method to attack NLI models using diverse logical forms of premise and hypothesis, providing a more robust evaluation of their performance. Our approach leverages a range of inference rules from propositional logic, such as Modus Tollens and Bidirectional Dilemma, to generate effective adversarial attacks and identify common vulnerabilities across multiple NLI models. We achieve an average {\textasciitilde}53{\%} Attack Success Rate (ASR) across multiple logic-based attacks. Moreover, we demonstrate that incorporating generated attack samples into training enhances the logical reasoning ability of the target model and decreases its vulnerability to logic-based attacks. Data and source code are available at https://github.com/msantoshmadhav/LogicAttack.",
}
          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>



<!-- -------- -->



<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances in QA</h5>
      <div class="author">
        <nobr><em>Neeraj Varshney</em></nobr> and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            Association for Computational Linguistics 2023
        
      </p>
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#postabstention-abstract" role="button" aria-expanded="false" aria-controls="postabstention-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#postabstention-bibtex" role="button" aria-expanded="false" aria-controls="postabstention-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2023.aclweb.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2023.acl-long.55/" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="postabstention-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Despite remarkable progress made in natural language processing, even the state-of-the-art models often make incorrect predictions. Such predictions hamper the reliability of systems and limit their widespread adoption in real-world applications. 'Selective prediction' partly addresses the above concern by enabling models to abstain from answering when their predictions are likely to be incorrect. While selective prediction is advantageous, it leaves us with a pertinent question 'what to do after abstention'. To this end, we present an explorative study on 'Post-Abstention', a task that allows re-attempting the abstained instances with the aim of increasing 'coverage' of the system without significantly sacrificing its 'accuracy'. We first provide mathematical formulation of this task and then explore several methods to solve it. Comprehensive experiments on 11 QA datasets show that these methods lead to considerable risk improvements --performance metric of the Post-Abstention task-- both in the in-domain and the out-of-domain settings. We also conduct a thorough analysis of these results which further leads to several interesting findings. Finally, we believe that our work will encourage and facilitate further research in this important area of addressing the reliability of NLP systems.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="postabstention-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @inproceedings{varshney-baral-2023-post,
    title = "Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances in {QA}",
    author = "Varshney, Neeraj  and
      Baral, Chitta",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.55",
    pages = "967--982",
    abstract = "Despite remarkable progress made in natural language processing, even the state-of-the-art models often make incorrect predictions. Such predictions hamper the reliability of systems and limit their widespread adoption in real-world applications. {`}Selective prediction{'} partly addresses the above concern by enabling models to abstain from answering when their predictions are likely to be incorrect. While selective prediction is advantageous, it leaves us with a pertinent question {`}what to do after abstention{'}. To this end, we present an explorative study on {`}Post-Abstention{'}, a task that allows re-attempting the abstained instances with the aim of increasing **coverage** of the system without significantly sacrificing its **accuracy**. We first provide mathematical formulation of this task and then explore several methods to solve it. Comprehensive experiments on 11 QA datasets show that these methods lead to considerable risk improvements {--}performance metric of the Post-Abstention task{--} both in the in-domain and the out-of-domain settings. We also conduct a thorough analysis of these results which further leads to several interesting findings. Finally, we believe that our work will encourage and facilitate further research in this important area of addressing the reliability of NLP systems.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>



<!-- -------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution</h5>
      <div class="author">
        <nobr><em>Neeraj Varshney*</em></nobr>,  <a href="https://scholar.google.com/citations?user=ydjuhxsAAAAJ&hl=en" target="_blank">Himanshu Gupta*</a>, <a href="https://scholar.google.com/citations?user=mLKCQM8AAAAJ&hl=en" target="_blank">Eric Robertson</a>, <a href="https://scholar.google.com/citations?user=Kt1bjZoAAAAJ&hl=en" target="_blank">Bing Liu</a>, and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            Findings of Association for Computational Linguistics 2023
        
      </p>
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#novelty-abstract" role="button" aria-expanded="false" aria-controls="novelty-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#novelty-bibtex" role="button" aria-expanded="false" aria-controls="novelty-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2023.aclweb.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2023.findings-acl.113/" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="novelty-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            State-of-the-art natural language processing models have been shown to achieve remarkable performance in 'closed-world' settings where all the labels in the evaluation set are known at training time. However, in real-world settings, `novel' instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of 'dealing with novelties', we introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance on pipelined novelty 'detection' and 'accommodation' tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use Amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results show that the methods achieve considerably low performance making the task challenging and leaving sufficient room for improvement. Finally, we believe our work will encourage research in this underexplored area of dealing with novelties, an important step en route to developing robust systems.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="novelty-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @inproceedings{varshney-etal-2023-unified,
    title = "A Unified Evaluation Framework for Novelty Detection and Accommodation in {NLP} with an Instantiation in Authorship Attribution",
    author = "Varshney, Neeraj  and
      Gupta, Himanshu  and
      Robertson, Eric  and
      Liu, Bing  and
      Baral, Chitta",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.113",
    pages = "1794--1818",
    abstract = "State-of-the-art natural language processing models have been shown to achieve remarkable performance in {`}closed-world{'} settings where all the labels in the evaluation set are known at training time. However, in real-world settings, {`}novel{'} instances that do not belong to any known class are often observed. This renders the ability to deal with novelties crucial. To initiate a systematic research in this important area of {`}dealing with novelties{'}, we introduce NoveltyTask, a multi-stage task to evaluate a system{'}s performance on pipelined novelty {`}detection{'} and {`}accommodation{'} tasks. We provide mathematical formulation of NoveltyTask and instantiate it with the authorship attribution task that pertains to identifying the correct author of a given text. We use amazon reviews corpus and compile a large dataset (consisting of 250k instances across 200 authors/labels) for NoveltyTask. We conduct comprehensive experiments and explore several baseline methods for the task. Our results show that the methods achieve considerably low performance making the task challenging and leaving sufficient room for improvement. Finally, we believe our work will encourage research in this underexplored area of dealing with novelties, an important step en route to developing robust systems.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>

<!-- -------- -->



<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          AAAI
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Can Open-Domain QA Reader Utilize External Knowledge Efficiently like Humans?</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://luomancs.github.io/", target="_blank">Man Luo</a>, and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            AAAI'23 Workshop on Knowledge Augmented Methods for NLP
        
      </p>
      <p  class="periodical font">
        <!-- <i>Do all instances need inference through the big models for a correct prediction?</i><br> 
        Perhaps not; some instances are easy and can be answered correctly by even small capacity models. This provides opportunities for improving the computational efficiency of systems. In this work, we present an explorative study on 'model cascading', a simple technique that utilizes a collection of models of varying capacities to accurately yet efficiently output predictions. Through comprehensive experiments in multiple task settings that differ in the number of models available for cascading (K value), we show that cascading improves both the computational efficiency and the prediction accuracy. For instance, in K=3 setting, cascading saves up to 88.93% computation cost and consistently achieves superior prediction accuracy with an improvement of up to 2.18%. We also study the impact of introducing additional models in the cascade and show that it further increases the efficiency improvements. Finally, we hope that our work will facilitate development of efficient NLP systems making their widespread adoption in real-world applications possible. -->

      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#odqa-abstract" role="button" aria-expanded="false" aria-controls="odqa-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#odqa-bibtex" role="button" aria-expanded="false" aria-controls="odqa-bibtex">BibTeX</a>                 
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://knowledge-nlp.github.io/aaai2023/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2211.12707" target="_blank">Paper</a>                

      </div>          
      
      <div class="col mt-2 p-0">
        <div id="odqa-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <div>Recent state-of-the-art open-domain QA models are typically based on a two stage retriever-reader approach in which the retriever first finds the relevant knowledge/passages and the reader then leverages that to predict the answer. Prior work has shown that the performance of the reader usually tends to improve with the increase in the number of these passages. Thus, state-of-the-art models use a large number of passages (e.g. 100) for inference. While the reader in this approach achieves high prediction performance, its inference is computationally very expensive. We humans, on the other hand, use a more efficient strategy while answering: firstly, if we can confidently answer the question using our already acquired knowledge then we do not even use the external knowledge, and in the case when we do require external knowledge, we don't read the entire knowledge at once, instead, we only read that much knowledge that is sufficient to find the answer. Motivated by this procedure, we ask a research question "Can the open-domain QA reader utilize external knowledge efficiently like humans without sacrificing the prediction performance?"</div>

            <div>Driven by this question, we explore an approach that utilizes both 'closed-book' (leveraging knowledge already present in the model parameters) and 'open-book' inference (leveraging external knowledge). Furthermore, instead of using a large fixed number of passages for open-book inference, we dynamically read the external knowledge in multiple 'knowledge iterations'. Through comprehensive experiments on NQ and TriviaQA datasets, we demonstrate that this dynamic reading approach improves both the 'inference efficiency' and the 'prediction accuracy' of the reader. Comparing with the FiD reader, this approach matches its accuracy by utilizing just 18.32% of its reader inference cost and also outperforms it by achieving up to 55.10% accuracy on NQ Open.</div>
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="odqa-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@article{varshney2022can,
  title={Can Open-Domain QA Reader Utilize External Knowledge Efficiently like Humans?},
  author={Varshney, Neeraj and Luo, Man and Baral, Chitta},
  journal={arXiv preprint arXiv:2211.12707},
  year={2022}
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>



<!-- -------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          EACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">"John is 50 years old, can his son be 65?" Evaluating NLP Models' Understanding of Feasibility</h5>
      <div class="author">
        <a href="https://scholar.google.com/citations?user=ydjuhxsAAAAJ&hl=en" target="_blank">Himanshu Gupta</a>, <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, <a href="https://kuntalkumarpal.github.io/" target="_blank">Kuntal Kumar Pal</a>, <a>Saurabh Arjun Sawant</a>, <a>Kevin Scaria</a>, <a>Siddharth Goyal</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            European Chapter of the Association for Computational Linguistics 2023
        
      </p>
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#feasibility-abstract" role="button" aria-expanded="false" aria-controls="feasibility-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#feasibility-bibtex" role="button" aria-expanded="false" aria-controls="feasibility-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2023.eacl.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2023.eacl-main.30/" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="feasibility-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            In current NLP research, large-scale language models and their abilities are widely being discussed. Some recent works have also found notable failures of these models. Often these failure examples involve complex reasoning abilities. This work focuses on a simple commonsense ability, reasoning about when an action (or its effect) is feasible. We introduce FeasibilityQA, a question-answering dataset involving binary classification (BCQ) and multi-choice multi-correct questions (MCQ) that test understanding of feasibility. We show that even state-of-the-art models such as GPT-3 struggle to answer the feasibility questions correctly. Specifically, on (MCQ, BCQ) questions, GPT-3 achieves accuracy of just (19%, 62%) and (25%, 64%) in zero-shot and few-shot settings, respectively. We also evaluate models by providing relevant knowledge statements required to answer the question and find that the additional knowledge leads to a 7% gain in performance, but the overall performance still remains low. These results make one wonder how much commonsense knowledge about action feasibility is encoded in GPT-3 and how well the model can reason about it.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="feasibility-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @inproceedings{gupta-etal-2023-john,
    title = "{``}John is 50 years old, can his son be 65?{''} Evaluating {NLP} Models{'} Understanding of Feasibility",
    author = "Gupta, Himanshu  and
      Varshney, Neeraj  and
      Mishra, Swaroop  and
      Pal, Kuntal Kumar  and
      Sawant, Saurabh Arjun  and
      Scaria, Kevin  and
      Goyal, Siddharth  and
      Baral, Chitta",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.30",
    pages = "407--417",
    abstract = "In current NLP research, large-scale language models and their abilities are widely being discussed. Some recent works have also found notable failures of these models. Often these failure examples involve complex reasoning abilities. This work focuses on a simple commonsense ability, reasoning about when an action (or its effect) is feasible. To this end, we introduce FeasibilityQA, a question-answering dataset involving binary classification (BCQ) and multi-choice multi-correct questions (MCQ) that test understanding of feasibility. We show that even state-of-the-art models such as GPT-3, GPT-2, and T5 struggle to answer the feasibility questions correctly. Specifically, on (MCQ, BCQ) questions, GPT-3 achieves accuracy of just (19{\%}, 62{\%}) and (25{\%}, 64{\%}) in zero-shot and few-shot settings, respectively. We also evaluate models by providing relevant knowledge statements required to answer the question and find that the additional knowledge leads to a 7{\%} gain in performance, but the overall performance still remains low. These results make one wonder how much commonsense knowledge about action feasibility is encoded in state-of-the-art models and how well they can reason about it.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>

<!-- -------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">On Dealing with Questions that Don't have Definitive Answers</h5>
      <div class="author">
        <nobr><em>Neeraj Varshney*</em></nobr>, Ayushi Agarwal*, Nisarg Patel*, Mihir Parmar, Pavan Mallina, Aryan Shah, Srihari Raju Sangaraju, Tirth Patel, Nihar Thakkar, and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            TrustNLP @ Association for Computational Linguistics 2023
        
      </p>
      <p  class="periodical font">
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#qnota-abstract" role="button" aria-expanded="false" aria-controls="qnota-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#qnota-bibtex" role="button" aria-expanded="false" aria-controls="qnota-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://trustnlpworkshop.github.io/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2309.04635" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="qnota-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Though state-of-the-art (SOTA) NLP systems have achieved remarkable performance on a variety of language understanding tasks, they primarily focus on questions that have a correct and a definitive answer. However, in real-world applications, users often ask questions that don't have a definitive answer. Incorrectly answering such questions certainly hampers a system's reliability and trustworthiness. Can SOTA models accurately identify such questions and provide a reasonable response?
            To investigate the above question, we introduce QnotA, a dataset consisting of five different categories of questions that don't have definitive answers. Furthermore, for each QnotA instance, we also provide a corresponding QA instance i.e. an alternate question that ''can be'' answered. With this data, we formulate three evaluation tasks that test a system's ability to 'identify', 'distinguish', and 'justify' QnotA questions. Through comprehensive experiments, we show that even SOTA models including GPT-3 and Flan T5 do not fare well on these tasks and lack considerably behind the human performance baseline. We conduct a thorough analysis which further leads to several interesting findings. Overall, we believe our work and findings will encourage and facilitate further research in this important area and help develop more robust models.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="qnota-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @article{agarwal2023can,
  title={Can NLP Models' Identify','Distinguish', and'Justify'Questions that Don't have a Definitive Answer?},
  author={Agarwal, Ayushi and Patel, Nisarg and Varshney, Neeraj and Parmar, Mihir and Mallina, Pavan and Shah, Aryan Bhavin and Sangaraju, Srihari Raju and Patel, Tirth and Thakkar, Nihar and Baral, Chitta},
  journal={arXiv preprint arXiv:2309.04635},
  year={2023}
}</pre>

          </div>
        </div>
      </div>
       

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>



<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          AAMAS
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Methods and Mechanisms for Interactive Novelty Handling in Adversarial Environments</h5>
      <div class="author">
        <a href="https://www.tungthai155.com/" target="_blank">Tung Thai</a>, <a href="https://scholar.google.com/citations?user=njWU4SEAAAAJ&hl=en" target="_blank">Ming Shen</a>, Mayang Garg, Ayush Kalani, Nakul Vaidya, <a href="https://scholar.google.com/citations?user=3Nqzr90AAAAJ&hl=en" target="_blank">Utkarsh Soni</a>, Mudit Verma, <a href="https://scholar.google.com/citations?user=So86Wl4AAAAJ&hl=en" target="_blank">Sriram Gopalakrishnan</a>, <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>, <a href="https://rakaposhi.eas.asu.edu/" target="_blank">Subbarao Kambhampati</a>, <a href="https://scholar.google.com/citations?user=-mHoWKEAAAAJ&hl=en" target="_blank">Jivko Sinapov</a>, <a href="https://scholar.google.com/citations?user=5yT3GScAAAAJ&hl=en" target="_blank">Matthias Scheutz</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            Extended Abstract at the Conference on Autonomous Agents and Multiagent Systems
        
      </p>
      <p  class="periodical font">
      </div>
    
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2023</h3>
    </div>
  </div>

<!-- -------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          EMNLP
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Model Cascading: Towards Jointly Improving Efficiency and Accuracy of NLP Systems</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr> and <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            Conference on Empirical Methods in Natural Language Processing
        
      </p>
      <p  class="periodical font">
        <!-- <i>Do all instances need inference through the big models for a correct prediction?</i><br> 
        Perhaps not; some instances are easy and can be answered correctly by even small capacity models. This provides opportunities for improving the computational efficiency of systems. In this work, we present an explorative study on 'model cascading', a simple technique that utilizes a collection of models of varying capacities to accurately yet efficiently output predictions. Through comprehensive experiments in multiple task settings that differ in the number of models available for cascading (K value), we show that cascading improves both the computational efficiency and the prediction accuracy. For instance, in K=3 setting, cascading saves up to 88.93% computation cost and consistently achieves superior prediction accuracy with an improvement of up to 2.18%. We also study the impact of introducing additional models in the cascade and show that it further increases the efficiency improvements. Finally, we hope that our work will facilitate development of efficient NLP systems making their widespread adoption in real-world applications possible. -->

      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cascading-abstract" role="button" aria-expanded="false" aria-controls="cascading-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#cascading-bibtex" role="button" aria-expanded="false" aria-controls="cascading-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2022.emnlp.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.emnlp-main.756/" target="_blank">Paper</a>                

      </div>          
      
      <div class="col mt-2 p-0">
        <div id="cascading-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <i>Do all instances need inference through the big models for a correct prediction?</i><br> 
        Perhaps not; some instances are easy and can be answered correctly by even small capacity models. This provides opportunities for improving the computational efficiency of systems. In this work, we present an explorative study on 'model cascading', a simple technique that utilizes a collection of models of varying capacities to accurately yet efficiently output predictions. Through comprehensive experiments in multiple task settings that differ in the number of models available for cascading (K value), we show that cascading improves both the computational efficiency and the prediction accuracy. For instance, in K=3 setting, cascading saves up to 88.93% computation cost and consistently achieves superior prediction accuracy with an improvement of up to 2.18%. We also study the impact of introducing additional models in the cascade and show that it further increases the efficiency improvements. Finally, we hope that our work will facilitate development of efficient NLP systems making their widespread adoption in real-world applications possible.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="cascading-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@inproceedings{varshney-baral-2022-model,
    title = "Model Cascading: Towards Jointly Improving Efficiency and Accuracy of {NLP} Systems",
    author = "Varshney, Neeraj  and
      Baral, Chitta",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.756",
    pages = "11007--11021",
    abstract = "Do all instances need inference through the big models for a correct prediction? Perhaps not; some instances are easy and can be answered correctly by even small capacity models. This provides opportunities for improving the computational efficiency of systems. In this work, we present an explorative study on {`}model cascading{'}, a simple technique that utilizes a collection of models of varying capacities to accurately yet efficiently output predictions. Through comprehensive experiments in multiple task settings that differ in the number of models available for cascading (K value), we show that cascading improves both the computational efficiency and the prediction accuracy. For instance, in K=3 setting, cascading saves up to 88.93{\%} computation cost and consistently achieves superior prediction accuracy with an improvement of up to 2.18{\%}. We also study the impact of introducing additional models in the cascade and show that it further increases the efficiency improvements. Finally, we hope that our work will facilitate development of efficient NLP systems making their widespread adoption in real-world applications possible.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          EMNLP
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks</h5>
      <div class="author">
        <a href="https://homes.cs.washington.edu/~yizhongw" target="_blank">Yizhong Wang</a>, <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, ..., <nobr><em>Neeraj Varshney</em></nobr>, ..., <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>, <a href="https://homes.cs.washington.edu/~yejin/" target="_blank">Yejin Choi</a>, <a href="https://homes.cs.washington.edu/~hannaneh/" target="_blank">Hannaneh Hajishirzi</a>, <a href="https://nasmith.github.io/" target="_blank">Noah A. Smith</a>, <a href="https://danielkhashabi.com/" target="_blank">Daniel Khashabi</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            Conference on Empirical Methods in Natural Language Processing
        
      </p>
      <!-- <p  class="periodical font">Prior work has shown that existing 'selective prediction' techniques fail to perform well, especially in the out-of-domain setting. In this work, we propose a method that improves probability estimates of models by calibrating them using prediction confidence and difficulty score of instances. Using these two signals, we first annotate held-out instances and then train a calibrator to predict the likelihood of correctness of the model's prediction. We instantiate our method with Natural Language Inference (NLI) and Duplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and Out-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the representations learned by our calibrator result in an improvement of (15.81%, 5.64%) and (6.19%, 13.9%) over MaxProb --a selective prediction baseline-- on NLI and DD tasks respectively.
      </div> -->
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#wang2022benchmarking-abstract" role="button" aria-expanded="false" aria-controls="wang2022benchmarking-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#wang2022benchmarking-bibtex" role="button" aria-expanded="false" aria-controls="wang2022benchmarking-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://2022.emnlp.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.emnlp-main.340/" target="_blank">Paper</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="wang2022benchmarking-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions—training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones.Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="wang2022benchmarking-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @inproceedings{wang-etal-2022-super,
    title = "Super-{N}atural{I}nstructions: Generalization via Declarative Instructions on 1600+ {NLP} Tasks",
    author = "Wang, Yizhong  and
      Mishra, Swaroop  and
      Alipoormolabashi, Pegah  and
      Kordi, Yeganeh  and
      Mirzaei, Amirreza  and
      Naik, Atharva  and
      Ashok, Arjun  and
      Dhanasekaran, Arut Selvan  and
      Arunkumar, Anjana  and
      Stap, David  and
      Pathak, Eshaan  and
      Karamanolakis, Giannis  and
      Lai, Haizhi  and
      Purohit, Ishan  and
      Mondal, Ishani  and
      Anderson, Jacob  and
      Kuznia, Kirby  and
      Doshi, Krima  and
      Pal, Kuntal Kumar  and
      Patel, Maitreya  and
      Moradshahi, Mehrad  and
      Parmar, Mihir  and
      Purohit, Mirali  and
      Varshney, Neeraj  and
      Kaza, Phani Rohitha  and
      Verma, Pulkit  and
      Puri, Ravsehaj Singh  and
      Karia, Rushang  and
      Doshi, Savan  and
      Sampat, Shailaja Keyur  and
      Mishra, Siddhartha  and
      Reddy A, Sujan  and
      Patro, Sumanta  and
      Dixit, Tanay  and
      Shen, Xudong",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.340",
    pages = "5085--5109",
    abstract = "How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions{---}training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones.Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9{\%} on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>



<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Unsupervised Natural Language Inference Using PHL Triplet Generation</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://pratyay-banerjee.github.io/" target="_blank">Pratyay Banerjee</a>, <a href="https://tejas-gokhale.github.io/" target="_blank">Tejas Gokhale</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            Findings of Association for Computational Linguistics
        
      </p>
      <p  class="periodical font">We explore three unsupervised settings for NLI and propose a procedural data generation approach that outperforms the existing approaches by ~13% and raises the state-of-the-art unsupervised performance on SNLI to 66.75%.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2021unsupervised-abstract" role="button" aria-expanded="false" aria-controls="varshney2021unsupervised-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2021unsupervised-bibtex" role="button" aria-expanded="false" aria-controls="varshney2021unsupervised-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.2022.aclweb.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.findings-acl.159/" target="_blank">Paper</a>      

          <a class="badge grey waves-effect font-weight-light mr-1" href="./Posters/UnsupervisedNLI.pdf" target="_blank">Poster</a>          
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="varshney2021unsupervised-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Transformer-based models achieve impressive performance on numerous Natural Language Inference (NLI) benchmarks when trained on respective training datasets. However, in certain cases, training samples may not be available or collecting them could be time-consuming and resource-intensive. In this work, we address the above challenge and present an explorative study on unsupervised NLI, a paradigm in which no human-annotated training samples are available. We investigate it under three settings: PH, P, and NPH that differ in the extent of unlabeled data available for learning. As a solution, we propose a procedural data generation approach that leverages a set of sentence transformations to collect PHL (Premise, Hypothesis, Label) triplets for training NLI models, bypassing the need for human-annotated training data. Comprehensive experiments with several NLI datasets show that the proposed approach results in accuracies of up to 66.75%, 65.9%, 65.39% in PH, P, and NPH settings respectively, outperforming all existing unsupervised baselines. Furthermore, fine-tuning our model with as little as ~0.1% of the human-annotated training dataset (500 instances) leads to 12.2% higher accuracy than the model trained from scratch on the same 500 instances. Supported by this superior performance, we conclude with a recommendation for collecting high-quality task-specific data.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="varshney2021unsupervised-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@inproceedings{varshney-etal-2022-unsupervised,
    title = "Unsupervised Natural Language Inference Using {PHL} Triplet Generation",
    author = "Varshney, Neeraj  and
      Banerjee, Pratyay  and
      Gokhale, Tejas  and
      Baral, Chitta",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.159",
    pages = "2003--2016",
    abstract = "Transformer-based models achieve impressive performance on numerous Natural Language Inference (NLI) benchmarks when trained on respective training datasets. However, in certain cases, training samples may not be available or collecting them could be time-consuming and resource-intensive. In this work, we address the above challenge and present an explorative study on unsupervised NLI, a paradigm in which no human-annotated training samples are available. We investigate it under three settings: PH, P, and NPH that differ in the extent of unlabeled data available for learning. As a solution, we propose a procedural data generation approach that leverages a set of sentence transformations to collect PHL (Premise, Hypothesis, Label) triplets for training NLI models, bypassing the need for human-annotated training data. Comprehensive experiments with several NLI datasets show that the proposed approach results in accuracies of up to 66.75{\%}, 65.9{\%}, 65.39{\%} in PH, P, and NPH settings respectively, outperforming all existing unsupervised baselines. Furthermore, fine-tuning our model with as little as {\textasciitilde}0.1{\%} of the human-annotated training dataset (500 instances) leads to 12.2{\%} higher accuracy than the model trained from scratch on the same 500 instances. Supported by this superior performance, we conclude with a recommendation for collecting high-quality task-specific data.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->



<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Investigating Selective Prediction Approaches Across Several Tasks in IID, OOD, and Adversarial Settings</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            Findings of Association for Computational Linguistics
        
      </p>
      <p  class="periodical font">Selective Prediciton enables systems to abstain from making predictions when they are likely to be incorrect. In this work, we systematically study 'selective prediction' in a large-scale setup of 17 datasets across several NLP tasks. We conduct experiments in in-domain, out-of-domain, and adversarial settings and evaluate several selective prediction approaches such as MaxProb, Monte-Carlo Dropout, Label Smoothing, and Calibration (C, R, and T). Our investigation results in numerous interesting findings.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2022investigating-abstract" role="button" aria-expanded="false" aria-controls="varshney2022investigating-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2022investigating-bibtex" role="button" aria-expanded="false" aria-controls="varshney2022investigating-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.2022.aclweb.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.findings-acl.158/" target="_blank">Paper</a>                

          <a class="badge grey waves-effect font-weight-light mr-1" href="./Posters/Investigating_SP.pdf" target="_blank">Poster</a>
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="varshney2022investigating-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            In order to equip NLP systems with selective prediction capability, several task-specific approaches have been proposed. However, which approaches work best across tasks or even if they consistently outperform the simplest baseline 'MaxProb' remains to be explored. To this end, we systematically study 'selective prediction' in a large-scale setup of 17 datasets across several NLP tasks. Through comprehensive experiments under in-domain (IID), out-of-domain (OOD), and adversarial (ADV) settings, we show that despite leveraging additional resources (held-out data/computation), none of the existing approaches consistently and considerably outperforms MaxProb in all three settings. Furthermore, their performance does not translate well across tasks. For instance, Monte-Carlo Dropout outperforms all other approaches on Duplicate Detection datasets but does not fare well on NLI datasets, especially in the OOD setting. Thus, we recommend that future selective prediction approaches should be evaluated across tasks and settings for reliable estimation of their capabilities.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="varshney2022investigating-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@inproceedings{varshney-etal-2022-investigating,
    title = "Investigating Selective Prediction Approaches Across Several Tasks in {IID}, {OOD}, and Adversarial Settings",
    author = "Varshney, Neeraj  and
      Mishra, Swaroop  and
      Baral, Chitta",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.158",
    pages = "1995--2002",
    abstract = "In order to equip NLP systems with {`}selective prediction{'} capability, several task-specific approaches have been proposed. However, which approaches work best across tasks or even if they consistently outperform the simplest baseline MaxProb remains to be explored. To this end, we systematically study selective prediction in a large-scale setup of 17 datasets across several NLP tasks. Through comprehensive experiments under in-domain (IID), out-of-domain (OOD), and adversarial (ADV) settings, we show that despite leveraging additional resources (held-out data/computation), none of the existing approaches consistently and considerably outperforms MaxProb in all three settings. Furthermore, their performance does not translate well across tasks. For instance, Monte-Carlo Dropout outperforms all other approaches on Duplicate Detection datasets but does not fare well on NLI datasets, especially in the OOD setting. Thus, we recommend that future selective prediction approaches should be evaluated across tasks and settings for reliable estimation of their capabilities.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">ILDAE: Instance-Level Difficulty Analysis of Evaluation Data</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            Association for Computational Linguistics
        
      </p>
      <p  class="periodical font">We conduct <b>I</b>nstance-<b>L</b>evel <b>D</b>ifficulty <b>A</b>nalysis of <b>E</b>valuation data (ILDAE) in a large-scale setup of 23 datasets and demonstrate its five novel applications such as efficient evaluations, improving quality of evaluation datasets, dataset analysis to guide future data creation, etc.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2022ildae-abstract" role="button" aria-expanded="false" aria-controls="varshney2022ildae-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2022ildae-bibtex" role="button" aria-expanded="false" aria-controls="varshney2022ildae-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.2022.aclweb.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.acl-long.240/" target="_blank">Paper</a>                

          <a class="badge grey waves-effect font-weight-light mr-1" href="./Posters/ILDAE.pdf" target="_blank">Poster</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="varshney2022ildae-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Knowledge of questions' difficulty level helps a teacher in several ways, such as estimating students' potential quickly by asking carefully selected questions and improving quality of examination by modifying trivial and hard questions. Can we extract such benefits of instance difficulty in NLP? To this end, we conduct Instance-Level Difficulty Analysis of Evaluation data (ILDAE) in a large-scale setup of 23 datasets and demonstrate its five novel applications: 1) conducting efficient-yet-accurate evaluations with fewer instances saving computational cost and time, 2) improving quality of existing evaluation datasets by repairing erroneous and trivial instances, 3) selecting the best model based on application requirements, 4) analyzing dataset characteristics for guiding future data creation, 5) estimating Out-of-Domain performance reliably. Comprehensive experiments for these applications result in several interesting findings, such as evaluation using just 5% instances (selected via ILDAE) achieves as high as 0.93 Kendall correlation with evaluation using complete dataset and computing weighted accuracy using difficulty scores leads to 5.2% higher correlation with Out-of-Domain performance. We release the difficulty scores and hope our analyses and findings will bring more attention to this important yet understudied field of leveraging instance difficulty in evaluations.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="varshney2022ildae-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@inproceedings{varshney-etal-2022-ildae,
    title = "{ILDAE}: Instance-Level Difficulty Analysis of Evaluation Data",
    author = "Varshney, Neeraj  and
      Mishra, Swaroop  and
      Baral, Chitta",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.240",
    pages = "3412--3425",
    abstract = "Knowledge of difficulty level of questions helps a teacher in several ways, such as estimating students{'} potential quickly by asking carefully selected questions and improving quality of examination by modifying trivial and hard questions. Can we extract such benefits of instance difficulty in Natural Language Processing? To this end, we conduct Instance-Level Difficulty Analysis of Evaluation data (ILDAE) in a large-scale setup of 23 datasets and demonstrate its five novel applications: 1) conducting efficient-yet-accurate evaluations with fewer instances saving computational cost and time, 2) improving quality of existing evaluation datasets by repairing erroneous and trivial instances, 3) selecting the best model based on application requirements, 4) analyzing dataset characteristics for guiding future data creation, 5) estimating Out-of-Domain performance reliably. Comprehensive experiments for these applications lead to several interesting results, such as evaluation using just 5{\%} instances (selected via ILDAE) achieves as high as 0.93 Kendall correlation with evaluation using complete dataset and computing weighted accuracy using difficulty scores leads to 5.2{\%} higher correlation with Out-of-Domain performance. We release the difficulty scores and hope our work will encourage research in this important yet understudied field of leveraging instance difficulty in evaluations.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- --------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">NumGLUE: A Suite of Mathematical Reasoning Tasks</h5>
      <div class="author">
        <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, <a href="https://scholar.google.com/citations?user=ItxA4esAAAAJ&hl=en" target="_blank">Arindam Mitra</a>, <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.com/citations?user=d0sZa-oAAAAJ&hl=en" target="_blank">Bhavdeep Singh Sachdeva</a>, <a href="https://allenai.org/team/peterc" target="_blank">Peter Clark</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>, <a href="http://ashwinkalyan.com/" target="_blank">Ashwin Kalyan</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            Association for Computational Linguistics
        
      </p>
      <p  class="periodical font">We proposed a multi-task benchmark that evaluates AI systems on eight different numerical understanding tasks and showed that it is far from being solved with neural models including large language models performing significantly worse than humans (lower by 46.4%).Proposed a knowledge-retrieval based MTL method that outperforms existing models.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#mishra2022numglue-abstract" role="button" aria-expanded="false" aria-controls="mishra2022numglue-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#mishra2022numglue-bibtex" role="button" aria-expanded="false" aria-controls="mishra2022numglue-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.2022.aclweb.org/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.acl-long.246/" target="_blank">Paper</a>   


      </div>          
      
      <div class="col mt-2 p-0">
        <div id="mishra2022numglue-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Given the ubiquitous nature of numbers in text, reasoning with numbers to perform simple calculations is an important skill of AI systems. While many datasets and models have been developed to this end, state-of-the-art AI systems are brittle; failing to perform the underlying mathematical reasoning when they appear in a slightly different scenario. Drawing inspiration from GLUE that was proposed in the context of natural language understanding, we propose NumGLUE, a multi-task benchmark that evaluates the performance of AI systems on eight different tasks, that at their core require simple arithmetic understanding. We show that this benchmark is far from being solved with neural models including state-of-the-art large-scale language models performing significantly worse than humans (lower by 46.4%). Further, NumGLUE promotes sharing knowledge across tasks, especially those with limited training data as evidenced by the superior performance (average gain of 3.4% on each task) when a model is jointly trained on all the tasks as opposed to task-specific modeling. Finally, we hope that NumGLUE will encourage systems that perform robust and general arithmetic reasoning within language, a first step towards being able to perform more complex mathematical reasoning.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="mishra2022numglue-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@inproceedings{mishra-etal-2022-numglue,
    title = "{N}um{GLUE}: A Suite of Fundamental yet Challenging Mathematical Reasoning Tasks",
    author = "Mishra, Swaroop  and
      Mitra, Arindam  and
      Varshney, Neeraj  and
      Sachdeva, Bhavdeep  and
      Clark, Peter  and
      Baral, Chitta  and
      Kalyan, Ashwin",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.246",
    pages = "3505--3523",
    abstract = "Given the ubiquitous nature of numbers in text, reasoning with numbers to perform simple calculations is an important skill of AI systems. While many datasets and models have been developed to this end, state-of-the-art AI systems are brittle; failing to perform the underlying mathematical reasoning when they appear in a slightly different scenario. Drawing inspiration from GLUE that was proposed in the context of natural language understanding, we propose NumGLUE, a multi-task benchmark that evaluates the performance of AI systems on eight different tasks, that at their core require simple arithmetic understanding. We show that this benchmark is far from being solved with neural models including state-of-the-art large-scale language models performing significantly worse than humans (lower by 46.4 {\%}). Further, NumGLUE promotes sharing knowledge across tasks, especially those with limited training data as evidenced by the superior performance (average gain of 3.4 {\%} on each task) when a model is jointly trained on all the tasks as opposed to task-specific modeling. Finally, we hope that NumGLUE will encourage systems that perform robust and general arithmetic reasoning within language, a first step towards being able to perform more complex mathematical reasoning.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->

<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          ACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Towards Improving Selective Prediction Ability of NLP Systems</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            Repl4NLP @ Association for Computational Linguistics
            
      </p>
      <p  class="periodical font">Prior work has shown that existing 'selective prediction' techniques fail to perform well, especially in the out-of-domain setting. In this work, we propose a method that improves probability estimates of models by calibrating them using prediction confidence and difficulty score of instances. Using these two signals, we first annotate held-out instances and then train a calibrator to predict the likelihood of correctness of the model's prediction. We instantiate our method with Natural Language Inference (NLI) and Duplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and Out-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the representations learned by our calibrator result in an improvement of (15.81%, 5.64%) and (6.19%, 13.9%) over MaxProb --a selective prediction baseline-- on NLI and DD tasks respectively.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2020s-abstract" role="button" aria-expanded="false" aria-controls="varshney2020s-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#varshney2020s-bibtex" role="button" aria-expanded="false" aria-controls="varshney2020s-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/view/repl4nlp2022/home?authuser=0" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.repl4nlp-1.23/" target="_blank">Paper</a>                

          <a class="badge grey waves-effect font-weight-light mr-1" href="./Posters/SP.pdf" target="_blank">Poster</a>
          
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="varshney2020s-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            It's better to say "I can't answer" than to answer incorrectly. This selective prediction ability is crucial for NLP systems to be reliably deployed in real-world applications. Prior work has shown that existing selective prediction techniques fail to perform well, especially in the out-of-domain setting. In this work, we propose a method that improves probability estimates of models by calibrating them using prediction confidence and difficulty score of instances. Using these two signals, we first annotate held-out instances and then train a calibrator to predict the likelihood of correctness of the model's prediction. We instantiate our method with Natural Language Inference (NLI) and Duplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and Out-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the representations learned by our calibrator result in an improvement of (15.81%, 5.64%) and (6.19%, 13.9%) over 'MaxProb' -- a selective prediction baseline -- on NLI and DD tasks respectively.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="varshney2020s-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
@inproceedings{varshney-etal-2022-towards,
    title = "Towards Improving Selective Prediction Ability of {NLP} Systems",
    author = "Varshney, Neeraj  and
      Mishra, Swaroop  and
      Baral, Chitta",
    booktitle = "Proceedings of the 7th Workshop on Representation Learning for NLP",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.repl4nlp-1.23",
    pages = "221--226",
    abstract = "It{'}s better to say {``}I can{'}t answer{''} than to answer incorrectly. This selective prediction ability is crucial for NLP systems to be reliably deployed in real-world applications. Prior work has shown that existing selective prediction techniques fail to perform well, especially in the out-of-domain setting. In this work, we propose a method that improves probability estimates of models by calibrating them using prediction confidence and difficulty score of instances. Using these two signals, we first annotate held-out instances and then train a calibrator to predict the likelihood of correctness of the model{'}s prediction. We instantiate our method with Natural Language Inference (NLI) and Duplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and Out-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the representations learned by our calibrator result in an improvement of (15.81{\%}, 5.64{\%}) and (6.19{\%}, 13.9{\%}) over {`}MaxProb{'} -a selective prediction baseline- on NLI and DD tasks respectively.",
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->


<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          NAACL
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Let the Model Decide its Curriculum for Multitask Learning</h5>
      <div class="author">
          <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.co.in/citations?user=-7LK2SwAAAAJ&hl=en" target="_blank">Swaroop Mishra</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>
      </div>
      <div>
        <p class="periodical font-italic">
          
            DeepLo @ North American Chapter of the Association for Computational Linguistics
            
        
      </p>
      <p  class="periodical font">We propose two classes of techniques to arrange training instances into a learning curriculum based on difficulty scores computed via model-based approaches. The two classes i.e Dataset-level and Instance-level differ in granularity of arrangement. Through comprehensive experiments with 12 datasets, we show that instance-level and dataset-level techniques result in strong representations as they  lead to an average performance improvement of 4.17% and 3.15% over their respective baselines. Furthermore, we find that most of this improvement comes from correctly answering the difficult instances, implying a greater efficacy of our techniques on difficult tasks.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#mtl-abstract" role="button" aria-expanded="false" aria-controls="mtl-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#mtl-bibtex" role="button" aria-expanded="false" aria-controls="mtl-bibtex">BibTeX</a>                
          
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/view/deeplo-2022/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/2022.deeplo-1.13/" target="_blank">Paper</a>    
          <a class="badge grey waves-effect font-weight-light mr-1" href="./Posters/MTL.pdf" target="_blank">Poster</a>            
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="mtl-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Curriculum learning strategies in prior multi-task learning approaches arrange datasets in a difficulty hierarchy either based on human perception or by exhaustively searching the optimal arrangement. However, human perception of difficulty may not always correlate well with machine interpretation leading to poor performance and exhaustive search is computationally expensive. Addressing these concerns, we propose two classes of techniques to arrange training instances into a learning curriculum based on difficulty scores computed via model-based approaches. The two classes i.e Dataset-level and Instance-level differ in granularity of arrangement. Through comprehensive experiments with 12 datasets, we show that instance-level and dataset-level techniques result in strong representations as they  lead to an average performance improvement of 4.17% and 3.15% over their respective baselines. Furthermore, we find that most of this improvement comes from correctly answering the difficult instances, implying a greater efficacy of our techniques on difficult tasks.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="mtl-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @inproceedings{varshney-mishra-and-chitta-baral-2022-model,
    title = "Let the Model Decide its Curriculum for Multitask Learning",
    author = "Varshney, Neeraj  and
      Mishra and Chitta Baral, Swaroop",
    booktitle = "Proceedings of the Third Workshop on Deep Learning for Low-Resource Natural Language Processing",
    month = jul,
    year = "2022",
    address = "Hybrid",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.deeplo-1.13",
    pages = "117--125",
    abstract = "t",
}

}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->



<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          AAAI
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">An Architecture for Novelty Handling in a Multi-Agent Stochastic Environment: Case Study in Open-World Monopoly</h5>
      <div class="author">
        <a href="https://www.tungthai155.com/" target="_blank">Tung Thai</a>, <a href="https://scholar.google.com/citations?user=njWU4SEAAAAJ&hl=en" target="_blank">Ming Shen</a>, <nobr><em>Neeraj Varshney</em></nobr>, <a href="https://scholar.google.com/citations?user=So86Wl4AAAAJ&hl=en" target="_blank">Sriram Gopalakrishnan</a>, <a href="https://scholar.google.com/citations?user=3Nqzr90AAAAJ&hl=en" target="_blank">Utkarsh Soni</a>, <a href="https://scholar.google.com/citations?user=5yT3GScAAAAJ&hl=en" target="_blank">Matthias Scheutz</a>, <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>, <a href="https://scholar.google.com/citations?user=-mHoWKEAAAAJ&hl=en" target="_blank">Jivko Sinapov</a>
          
      </div>
      <div>
        <p class="periodical font-italic">
          
            AAAI Spring Symposium 2022
        
      </p>
      <p  class="periodical font">We introduce an architecture that allows agents to detect novelties, characterize those novelties, and build an appropriate adaptive model to accommodate them.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#aaaisymp-abstract" role="button" aria-expanded="false" aria-controls="aaaisymp-abstract">Abstract</a>        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#aaaisymp-bibtex" role="button" aria-expanded="false" aria-controls="aaaisymp-bibtex">BibTeX</a>                
           -->
            <a class="badge grey waves-effect font-weight-light mr-1" href="https://usc-isi-i2.github.io/AAAI2022SS/" target="_blank">Publisher</a>                  
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://usc-isi-i2.github.io/AAAI2022SS/papers/SSS-22_paper_50.pdf" target="_blank">arXiv</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="aaaisymp-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            The ability of AI agents and architectures to detect and adapt to sudden changes in their environments remains an outstanding challenge. In the context of multi-agent games, the agent may face novel situations where the rules of the game, the available actions, the environment dynamics, the behavior of other agents, as well as the agent’s goals suddenly change. In this paper, we introduce an architecture that allows agents to detect novelties, characterize those novelties, and build an appropriate adaptive model to accommodate them. Our agent utilizes logic and reasoning (specifically, Answer Set Programming) to characterize novelties into different categories, as to enable the agent to adapt to the novelty while maintaining high performance in the game. We demonstrate the effectiveness of the proposed agent architecture in a multi-agent imperfect information board game, Monopoly. We measure the success of the architecture by comparing our method to heuristics, and vanilla Monte-Carlo Tree Search approaches. Our results indicate precise novelty detection, and significant improvements in the performance of agents utilizing the novelty handling architecture.
          </div>
        </div>
      </div>
            
      <!-- <div class="col mt-2 p-0">
        <div id="wang2022benchmarking-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @article{wang2022benchmarking,
  title={Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal={arXiv preprint arXiv:2204.07705},
  year={2022}
}</pre>

          </div>
        </div>
      </div>
       -->

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
  </div>

<!-- -------- -->







<div class="row m-0 p-0" style="border-top: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography">

        <li><div class="row m-0 mt-3 p-0">
      <div class="col-sm-1 p-0 abbr">
    
      
        <span class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;">
          arXiv
        </span>
      
    
      </div>
  
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="verma2022learninguser" class="col p-0">
      <h5 class="title mb-0">Can Transformers Reason About Effects of Actions?</h5>
      <div class="author">
          <a href="https://pratyay-banerjee.github.io/" target="_blank">Pratyay Banerjee</a>,
                <a href="https://www.public.asu.edu/~cbaral/" target="_blank">Chitta Baral</a>,
                <a href="https://luomancs.github.io/" target="_blank">Man Luo</a>,
                <a href="https://scholar.google.com/citations?user=ItxA4esAAAAJ&hl=en" target="_blank">Arindam Mitra</a>, 
                <a href="https://kuntalkumarpal.github.io/" target="_blank">Kuntal Pal</a>,
                <a href="https://www.cs.nmsu.edu/~tson/" target="_blank">Tran C. Son</a>,
                <nobr><em>Neeraj Varshney</em></nobr>
          
      </div>
      <div>
        <p class="periodical font-italic">
          arXiv          
        
      </p>
      <p  class="periodical font">Reasoning about action and change has been a top focus in the knowledge representation subfield of AI from the early days of AI and more recently it has been a highlight aspect in common sense question answering. We consider four action domains (Blocks World, Logistics, Dock-Worker-Robots and a Generic Domain) in natural language and create QA datasets that involve reasoning about the effects of actions in these domains. We investigate the ability of transformers to (a) learn to reason in these domains and (b) transfer that learning from the generic domains to the other domains.
      </div>
    
      <div class="col p-0">        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#banerjee2020can-abstract" role="button" aria-expanded="false" aria-controls="banerjee2020can-abstract">Abstract</a>        
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#banerjee2020can-bibtex" role="button" aria-expanded="false" aria-controls="banerjee2020can-bibtex">BibTeX</a>                
          
            <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2012.09938" target="_blank">Publisher</a>                  
         -->
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://arxiv.org/abs/2012.09938" target="_blank">arXiv</a>                
      </div>          
      
      <div class="col mt-2 p-0">
        <div id="banerjee2020can-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            A recent work has shown that transformers are able to "reason" with facts and rules in a limited setting where the rules are natural language expressions of conjunctions of conditions implying a conclusion. Since this suggests that transformers may be used for reasoning with knowledge given in natural language, we do a rigorous evaluation of this with respect to a common form of knowledge and its corresponding reasoning -- the reasoning about effects of actions. Reasoning about action and change has been a top focus in the knowledge representation subfield of AI from the early days of AI and more recently it has been a highlight aspect in common sense question answering. We consider four action domains (Blocks World, Logistics, Dock-Worker-Robots and a Generic Domain) in natural language and create QA datasets that involve reasoning about the effects of actions in these domains. We investigate the ability of transformers to (a) learn to reason in these domains and (b) transfer that learning from the generic domains to the other domains.
          </div>
        </div>
      </div>
            
      <div class="col mt-2 p-0">
        <div id="banerjee2020can-bibtex" class="collapse">
          <div class="bibtex card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <pre>
          @article{banerjee2020can,
  title={Can Transformers Reason About Effects of Actions?},
  author={Banerjee, Pratyay and Baral, Chitta and Luo, Man and Mitra, Arindam and Pal, Kuntal and Son, Tran C and Varshney, Neeraj},
  journal={arXiv preprint arXiv:2012.09938},
  year={2020}
}</pre>

          </div>
        </div>
      </div>
      

      
      
    </div>

  </div>
  
</div>


</li>

</ol>
    </div>
    <div class="col-sm-1 align-self-start mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2020</h3>
    </div>
  </div>

<!-- -------- -->



  
  <!-- Core JavaScript Files -->
  <script src="../assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="../assets/js/popper.min.js" type="text/javascript"></script>
  <script src="../assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="../assets/js/common.js"></script>

  <!-- GitHub Stars -->
  <script src="../assets/js/github-stars.js"></script>
  <script type="text/javascript">
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="../assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
